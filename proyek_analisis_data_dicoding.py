# -*- coding: utf-8 -*-
"""Proyek Analisis Data dicoding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A1CVUT-pucK1mxLgDzvu8hWmvt2kyda2

# Proyek Analisis Data: [E-commerce-public-dataset]
- **Nama:** Muhammad Syafiq Fadhilah
- **Email:** msyafiqfadhilah333@gmail.com
- **ID Dicoding:** syafiq333

## Menentukan Pertanyaan Bisnis
"""



"""- Bagaimana cara mengetahui 10 produk dengan penjualan terlaris dengan grafik?
- Buktikan dengan grafik apakah ada pergeseran tren penjualan produk?

## Import Semua Packages/Library yang Digunakan
"""

import pandas as pd #Python Data Analysis Library
import numpy as np #Python Scientific Library (Umumnya membantu
#dalam urusan list)
import matplotlib.pyplot as plt
import seaborn as sns
#Selective import modul-modul Scikit Learn
#(Scikit Learn memiliki banyak modul machine learning)
from sklearn import linear_model
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

from google.colab import drive
drive.mount('/content/drive')

import os                                                                         #Mengimpor modul os mengakses folder data
import zipfile                                                                    #Mengimpor modul zipfile untuk membaca file zip

local_zip = '/content/drive/MyDrive/Colab Notebooks/Dataset/E-commerce-public-dataset.zip'                                      #Mendefinisikan file zip yang akan diekstrak
zip_ref = zipfile.ZipFile(local_zip, 'r')                                         #Mengekstrak file zip
zip_ref.extractall('/content/')                                                   #Menempatkan file hasil ekstrak zip
zip_ref.close()                                                                   #Menghentikan fungsi zip.ref

"""## Data Wrangling

### Gathering Data

1. Memuat data customer
"""

customers_df = pd.read_csv("/content/E-Commerce Public Dataset/customers_dataset.csv")
customers_df.head(10)

"""2. Memuat data geolocation"""

geolocation_df = pd.read_csv("/content/E-Commerce Public Dataset/geolocation_dataset.csv")
geolocation_df.head()

"""3. Memuat data order item"""

order_items_df = pd.read_csv("/content/E-Commerce Public Dataset/order_items_dataset.csv")
order_items_df.head()

"""4. Memuat data order payments"""

order_payments_df = pd.read_csv("/content/E-Commerce Public Dataset/order_payments_dataset.csv")
order_payments_df.head()

"""5. Memuat data order review"""

order_reviews_df = pd.read_csv("/content/E-Commerce Public Dataset/order_reviews_dataset.csv")
order_reviews_df.head()

"""6. Memuat data orders"""

orders_df = pd.read_csv("/content/E-Commerce Public Dataset/orders_dataset.csv")
orders_df.head()

"""7. Memuat data product category"""

product_category_name_df = pd.read_csv("/content/E-Commerce Public Dataset/product_category_name_translation.csv")
product_category_name_df.head()

product_category_name_df.describe(include="all")

"""8. Memuat data products"""

products_df = pd.read_csv("/content/E-Commerce Public Dataset/products_dataset.csv")
products_df.head()

"""9. Memuat data seller"""

sellers_df = pd.read_csv("/content/E-Commerce Public Dataset/sellers_dataset.csv")
sellers_df.head()

"""**Insight:**
- setelah melihat satu persatu dari data e-commerce, dapat disimpulkan bahwa sebagian besar datanya masih kotor. masih terdapat missing value, dan duplikasi data.

### Assessing Data

1. Menilai data customer
"""

customers_df.info()

customers_df.isna().sum()

print("Jumlah duplikasi: ", customers_df.duplicated().sum())
customers_df.describe()

"""2. Menilai geolocation dataset"""

geolocation_df.info()

geolocation_df.isna().sum()

print("Jumlah duplikasi: ", geolocation_df.duplicated().sum())
geolocation_df.describe()

"""3. Menilai order items"""

order_items_df.info()

order_items_df.isna().sum()

datetime_columns = ["shipping_limit_date"]
for column in datetime_columns:
  order_items_df[column] = pd.to_datetime(order_items_df[column])

print("Jumlah duplikasi: ", order_items_df.duplicated().sum())
order_items_df.describe()



"""4. Menilai orders payment"""

order_payments_df.info()

order_payments_df.isna().sum()

print("Jumlah duplikasi: ", order_payments_df.duplicated().sum())
order_payments_df.describe()

"""5. Menilai order_reviews"""

order_reviews_df.info()

"""Mengecek missing value"""

order_reviews_df.isna().sum()

"""Mengecek duplikasi data"""

print("jumlah duplikasi: ", order_reviews_df.duplicated().sum())

order_reviews_df.describe()

"""6. Menilai order dataset"""

orders_df.info()

"""Mengecek missing value"""

orders_df.isna().sum()

print("jumlah duplikasi: ", orders_df.duplicated().sum())

orders_df.describe()

"""7. menilai product category"""

product_category_name_df.info()

"""mengecek missing value"""

product_category_name_df.isna().sum()

print("jumlah duplikasi: ", product_category_name_df.duplicated().sum())

"""8. mengecek product dataset"""

products_df.info()

products_df.isna().sum()

print("jumlah duplikasi: ", products_df.duplicated().sum())

products_df.describe()

"""9. Mengecek data sellers"""

sellers_df.info()

"""mengecek missing value"""

sellers_df.isna().sum()

print("jumlah duplikasi: ", sellers_df.duplicated().sum())

sellers_df.describe()

"""**Insight:**
Setelah dilakukan assessing data, ternyata terdapat beberapa kesalahan, missing value, duplikasi data pada data diatas. antara lain.
- geolocation
terdapat duplikasi data

- order reviews
terdapat missing value pada review comment title dan review comment message
- order dataset
terdapat missing value pada order approved at, order delivered carier date, order delivered customer date
- product dataset
terdapat missing value dari product category name sampai product width cm

### Cleaning Data

- Menangani duplikasi data
"""

geolocation_df.drop_duplicates(inplace=True)

print("Jumlah duplikasi: ", geolocation_df.duplicated().sum())

geolocation_df.isna().sum()

"""- Menangani missing value"""

order_reviews_df[order_reviews_df['review_comment_title'].isna()]

order_reviews_df.review_comment_title.value_counts()

order_reviews_df.fillna(value='No Title', inplace=True)

order_reviews_df.isna().sum()

products_df[products_df['product_category_name'].isna()]

products_df.product_category_name.value_counts()

products_df.fillna(value='No Category', inplace=True)

products_df.isna().sum()

order_reviews_df[order_reviews_df.review_comment_message.isna()]

order_reviews_df.review_comment_message.value_counts()

order_reviews_df.fillna(value='No Message', inplace=True)

order_reviews_df.isna().sum()

"""**Insight:**

setelah melakukan proses cleaning data, data yang semula terdapat missing value, duplicate sudah tertangani

## Exploratory Data Analysis (EDA)

### Explore ...

1. eksplorasi customers_dataset
"""

customers_df.describe(include="all")

customers_df.groupby(by="customer_city").customer_id.nunique().sort_values(ascending=False)
customers_df.groupby(by="customer_state").customer_id.nunique().sort_values(ascending=False)

"""2. geolocation dataset"""

geolocation_df.describe(include="all")

geolocation_df.groupby(by="geolocation_city").geolocation_zip_code_prefix.nunique().sort_values(ascending=False)
geolocation_df.groupby(by="geolocation_state").geolocation_zip_code_prefix.nunique().sort_values(ascending=False)

"""3. Order Items dataset"""

order_items_df.describe(include="all")

order_items_df.groupby(by="product_id").agg(
    {
        "order_item_id": "count",
        "price": ["min", "max", "mean", "std"]
    }
)

shipping_limit_date_df = order_items_df["shipping_limit_date"]-order_items_df["shipping_limit_date"]
shipping_limit_date_df = shipping_limit_date_df.apply(lambda x: x.total_seconds())
orders_df["shipping_limit_date_df"] = round(shipping_limit_date_df/86400)

"""4. Order payments dataset"""

order_payments_df.describe(include="all")

"""5. order review dataset"""

order_reviews_df.describe(include="all")

"""## Visualization & Explanatory Analysis

### Pertanyaan 1: Mengetahui Visualisasi Produk terlaris
"""

# Menggabungkan dataset
merged_data = pd.merge(orders_data, order_items_data, on='order_id', how='inner')

# Menghitung jumlah penjualan per produk
product_sales = merged_data['product_id'].value_counts().head(10)

# Visualisasi produk terlaris
plt.figure(figsize=(12, 6))
sns.barplot(x=product_sales.index, y=product_sales.values, palette='viridis')
plt.title('Top 10 Best Selling Products')
plt.xlabel('Product ID')
plt.ylabel('Number of Sales')
plt.xticks(rotation=45)
plt.show()

"""### Pertanyaan 2: tren penjualan berdasarkan waktu"""

# Memuat ulang data dengan kolom tanggal
merged_data['order_purchase_timestamp'] = pd.to_datetime(merged_data['order_purchase_timestamp'])

# Menghitung jumlah pesanan per bulan
monthly_sales = merged_data.set_index('order_purchase_timestamp').resample('M').size()

# Visualisasi tren penjualan bulanan
plt.figure(figsize=(12, 6))
monthly_sales.plot()
plt.title('Monthly Sales Trend')
plt.xlabel('Date')
plt.ylabel('Number of Orders')
plt.show()

"""**Insight:**
- pada permasalahan pertama, menunjukkan bahwa dari grafik bahwa ada 10 produk dengan penjualan terlaris
- pada permasalahan kedua, menunjukkan bahwa adanya pergeseran tren penjualan produk yang sangat signifikan

## Analisis Lanjutan (Opsional)
"""

import pandas as pd

# Memuat dataset
orders_file_path = '/content/E-Commerce Public Dataset/orders_dataset.csv'  # Ganti dengan path file Anda
order_items_file_path = '/content/E-Commerce Public Dataset/order_items_dataset.csv'  # Ganti dengan path file Anda

orders_data = pd.read_csv(orders_file_path)
order_items_data = pd.read_csv(order_items_file_path)

print(orders_data.head())
print(order_items_data.head())

# Menggabungkan dataset
merged_data = pd.merge(orders_data, order_items_data, on='order_id', how='inner')

print(merged_data.head())

# Mengubah kolom timestamp menjadi tipe datetime
merged_data['order_purchase_timestamp'] = pd.to_datetime(merged_data['order_purchase_timestamp'])

# Menentukan tanggal referensi untuk perhitungan recency
reference_date = merged_data['order_purchase_timestamp'].max() + pd.DateOffset(1)

# Menghitung Recency, Frequency, dan Monetary
rfm_table = merged_data.groupby('customer_id').agg({
    'order_purchase_timestamp': lambda x: (reference_date - x.max()).days,  # Recency
    'order_id': 'count',  # Frequency
    'price': 'sum'  # Monetary (Ganti 'price' dengan nama kolom yang sesuai untuk total pengeluaran)
}).reset_index()

# Mengganti nama kolom
rfm_table.rename(columns={
    'order_purchase_timestamp': 'Recency',
    'order_id': 'Frequency',
    'price': 'Monetary'
}, inplace=True)

print(rfm_table.head())

# Memberikan skor untuk setiap metrik
rfm_table['R_Score'] = pd.qcut(rfm_table['Recency'], 4, ['4', '3', '2', '1'])
rfm_table['F_Score'] = pd.qcut(rfm_table['Frequency'].rank(method='first'), 4, ['1', '2', '3', '4'])
rfm_table['M_Score'] = pd.qcut(rfm_table['Monetary'], 4, ['1', '2', '3', '4'])

# Menggabungkan skor menjadi satu skor RFM
rfm_table['RFM_Score'] = rfm_table['R_Score'].astype(str) + rfm_table['F_Score'].astype(str) + rfm_table['M_Score'].astype(str)

print(rfm_table.head())

# Definisi segmentasi berdasarkan skor RFM
def rfm_segment(df):
    if df['RFM_Score'] in ['444', '443', '434', '433']:
        return 'Best Customers'
    elif df['RFM_Score'] in ['344', '334', '343', '333']:
        return 'Loyal Customers'
    elif df['RFM_Score'] in ['244', '234', '243', '233']:
        return 'Potential Loyalists'
    elif df['RFM_Score'] in ['144', '134', '143', '133']:
        return 'Recent Customers'
    elif df['RFM_Score'] in ['444', '433', '422', '412']:
        return 'Promising'
    elif df['RFM_Score'] in ['244', '234', '223', '213']:
        return 'Customers Needing Attention'
    elif df['RFM_Score'] in ['144', '134', '123', '113']:
        return 'About To Sleep'
    elif df['RFM_Score'] in ['122', '112', '111', '121']:
        return 'At Risk'
    elif df['RFM_Score'] in ['322', '312', '211', '221']:
        return 'Cannot Lose Them'
    else:
        return 'Other'

# Menambahkan kolom segmentasi
rfm_table['Segment'] = rfm_table.apply(rfm_segment, axis=1)

print(rfm_table.head())

"""## Conclusion

- data diatas berhasil keluar outputnya setelah menerapkan teknik analisis lanjutan

Menyimpan semua file ke dalam 1 csv
"""

import pandas as pd
import os

# Path ke folder tempat file CSV diekstrak
dataset_path = '/content/E-Commerce Public Dataset'

# List nama file CSV yang telah dibersihkan
file_names = ['customers_dataset.csv', 'geolocation_dataset.csv',
              'order_items_dataset.csv', 'order_reviews_dataset.csv',
              'orders_dataset.csv', 'product_category_name_translation.csv',
              'products_dataset.csv', 'sellers_dataset.csv']

# List untuk menyimpan DataFrame
dfs = []

# Loop untuk membaca setiap file CSV dan menambahkannya ke list dfs
for file_name in file_names:
    # Gabungkan path folder dan nama file
    full_path = os.path.join(dataset_path, file_name)
    df = pd.read_csv(full_path)
    dfs.append(df)

# Gabungkan semua DataFrame dalam list dfs
all_df = pd.concat(dfs, ignore_index=True)

# Simpan DataFrame yang telah digabungkan ke dalam satu file CSV
all_df.to_csv('all_data.csv', index=False)